{"cells":[{"cell_type":"markdown","source":["#### Defining function to load data into dim_city table"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b4c8ab4a-a077-44ac-b675-c943ed033169","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def load_cities():\n    from pyspark.sql.functions import col\n    # read city from json file\n    file_path = \"dbfs:/FileStore/shared_uploads/koushalashmin@gmail.com/city_list_json.gz\"\n    options = {'multiLine': True}\n    df = spark.read.json(file_path, **options).select('*', 'coord.*')\n    df = df.select(col('id').cast('int'), 'name', 'country', col('lat').cast('float'), col('lon').cast('float'))\n    df = df.filter(df[\"country\"] == \"NP\")   \n    df.write.format('delta').mode('overwrite').saveAsTable('dim_city')\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"1da39e39-af68-402f-838c-01046bd9c9a3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"city_utils","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":682576924870976,"dataframes":["_sqldf"]}},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
