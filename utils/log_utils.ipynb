{"cells":[{"cell_type":"markdown","source":["#### Defining log table"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e8b9e8d5-edfb-4398-996b-bdb085d30c45","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def create_log_table():\n\n    query = \"\\\n        CREATE TABLE IF NOT EXISTS weather_log_table (\\\n        id STRING,\\\n        load_type STRING,\\\n        table_name STRING,\\\n        process_start_time TIMESTAMP,\\\n        process_end_time TIMESTAMP,\\\n        status STRING,\\\n        comments STRING,\\\n        start_date_time TIMESTAMP,\\\n        end_date_time TIMESTAMP,\\\n        created_on TIMESTAMP,\\\n        created_by STRING\\\n        )\\\n        USING DELTA;\\\n    \"\n    spark.sql(query)\n    \n    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000,"implicitDf":true},"nuid":"259cff01-bbb9-4d61-816c-317b4d13fb09","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Defining log decorator"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c60909d0-ec88-48eb-bfd1-c14c5bb7dee2","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def keep_log(func):\n    def wrapper(*args, **kwargs):\n        \n        import uuid\n        from datetime import datetime\n        from pyspark.sql.functions import col, udf\n        from pyspark.sql.types import TimestampType\n\n        id = str(uuid.uuid4())\n        load_type = args[0]\n        table_name = args[1]\n        process_start_dt = datetime.now()\n        name = 'Ashmin Bhattarai'\n        status = 'EXTRACTING'\n\n        query = f\"insert into weather_log_table (id, load_type, table_name, process_start_time, status, created_on, created_by)\\\n            values ('{id}', '{load_type}', '{table_name}', '{process_start_dt}', '{status}', '{process_start_dt}', '{name}')\"\n        spark.sql(query)\n        \n        try:\n            df, start, end = func(*args[2:], **kwargs)\n            status = 'COMPLETED'\n        except Exception as e:\n            status = 'ERROR'\n            process_end_dt = datetime.now()\n            query = f\"update weather_log_table \\\n                        set process_end_time = '{process_end_dt}', status='{status}', comments='{e}',\\\n                        where id='{id}'\"\n            spark.sql(query)\n            dbutils.notebook.exit(1)\n        \n        udf_id = udf(lambda : id)\n        udf_created_on = udf(lambda : process_start_dt, TimestampType())\n        udf_created_by = udf(lambda : name)\n        \n        df = df.withColumn('load_run_id', udf_id())\n        df = df.withColumn('created_on', udf_created_on())\n        df = df.withColumn('created_by', udf_created_by())\n        \n        df.write.format('delta').mode('append').saveAsTable(table_name)\n        \n        process_end_dt = datetime.now()\n        query = f\"update weather_log_table \\\n                    set process_end_time = '{process_end_dt}', status='{status}', start_date_time='{start}',\\\n                        end_date_time='{end}'\\\n                    where id='{id}'\"\n        spark.sql(query)\n        \n        return df\n    \n    return wrapper\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"eb509f51-68b6-4dc7-9718-1349d0dd20a6","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"log_utils","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":-1,"dataframes":["_sqldf"]}},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
