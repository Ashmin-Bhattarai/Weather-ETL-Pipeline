{"cells":[{"cell_type":"markdown","source":["#### Defining function to get fact data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"30bf5a47-d788-4419-907e-58ba3a3b06dc","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["@keep_log\ndef get_hourly_fact_weather(df):\n    \n    from datetime import datetime\n    from pyspark.sql.functions import hour, col\n    \n    df = df.withColumn('timeID', hour('created_on')).withColumn('Date', col('created_on').cast('date'))\n    \n    try:\n        # df_hourly_fact = spark.table('hourly_fact_weather')\n        timeID, date = df.select('timeID', 'Date').first()\n        dateID = str(date).replace('-', '')\n        query = f\"delete from hourly_fact_weather where timeID='{timeID}' and dateID='{dateID}';\"\n        spark.sql(query)\n    except:\n        pass\n    \n    df_date = spark.table('dim_date')\n    df_fact = df.join(df_date, df.Date == df_date.fullDate).select(\n                            df.timeID,\n                            df_date.dateID,\n                            df.city_id,\n                            df.temp,\n                            df.temp_min,\n                            df.temp_max,\n                            df.pressure,\n                            df.humidity,\n                            df.visibility,\n                            df.wind_speed,\n                            df.wind_deg,\n                            df.wind_gust,\n                            df.clouds_all\n                        )\n    start = datetime.fromtimestamp(df.selectExpr(\"min(dt)\").first()[0])\n    end = datetime.fromtimestamp(df.selectExpr(\"max(dt)\").first()[0])\n    \n    return df_fact, start, end"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ddbd6727-41ad-44a7-b6f4-e80631f808fc","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["@keep_log\ndef get_daily_fact_weather(df):\n    \n    from datetime import datetime\n    from pyspark.sql.functions import hour, col, min, max, mean\n    \n    df = df.withColumn('Date', col('created_on').cast('date'))  \n    \n    df_date = spark.table('dim_date')\n    \n    df_fact = df.join(df_date, df.Date == df_date.fullDate).select(\n                            df_date.dateID,\n                            df.city_id,\n                            df.temp,\n                            df.temp_min,\n                            df.temp_max,\n                            df.pressure,\n                            df.humidity,\n                            df.visibility,\n                            df.wind_speed,\n                            df.wind_deg,\n                            df.wind_gust,\n                            df.clouds_all\n                        )\n    \n    df_daily_fact = df_fact.alias('df_daily_fact')\n    \n    try:\n        date = df.select('Date').first()[0]\n        dateID = str(date).replace('-', '')\n#         print(\"============>>>\", dateID)\n        df_daily_fact = spark.sql(f\"select * from daily_fact_weather where dateID='{dateID}';\")\\\n                            .drop('load_run_id', 'created_on', 'created_by')\n        \n#         display(df_daily_fact)\n        \n        spark.sql(f\"delete from daily_fact_weather where dateID='{dateID}';\")\n    except:\n        df_daily_fact = df_fact.alias('df_daily_fact')\n    \n    \n    df_fact = df_fact.union(df_daily_fact).groupBy(col('city_id'), col('dateID'))\\\n                    .agg(mean(\"temp\").alias('temp'), \n                         min('temp_min').alias('temp_min'), \n                         max('temp_max').alias('temp_max'), \n                         mean('pressure').cast('int').alias('pressure'), \n                         mean('humidity').cast('int').alias('humidity'), \n                         mean('visibility').cast('int').alias('visibility'),\n                         mean('wind_speed').cast('int').alias('wind_speed'),\n                         mean('wind_deg').cast('int').alias('wind_deg'), \n                         mean('wind_gust').alias('wind_gust'),\n                         mean('clouds_all').alias('clouds_all'),\n                        )\n    \n    \n    start = datetime.fromtimestamp(df.selectExpr(\"min(dt)\").first()[0])\n    end = datetime.fromtimestamp(df.selectExpr(\"max(dt)\").first()[0])\n    \n    return df_fact, start, end"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"34caa900-eba5-4dd0-a332-9c8b184ece61","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"fact_weather_utils","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":4179411396049407,"dataframes":["_sqldf"]}},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
