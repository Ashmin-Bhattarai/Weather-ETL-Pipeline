{"cells":[{"cell_type":"markdown","source":["#### Defining function to get fact data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"30bf5a47-d788-4419-907e-58ba3a3b06dc","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["@keep_log\ndef get_hourly_fact_weather(df):\n    \n    from datetime import datetime\n    from pyspark.sql.functions import hour, col\n    \n    df = df.withColumn('timeID', hour('created_on')).withColumn('Date', col('created_on').cast('date'))\n    \n    try:\n        # df_hourly_fact = spark.table('hourly_fact_weather')\n        timeID, date = df.select('timeID', 'Date').first()\n        dateID = str(date).replace('-', '')\n        query = f\"delete from hourly_fact_weather where timeID='{timeID}' and dateID='{dateID}';\"\n        spark.sql(query)\n    except:\n        pass\n    \n    df_date = spark.table('dim_date')\n    df_fact = df.join(df_date, df.Date == df_date.fullDate).select(\n                            df.timeID,\n                            df_date.dateID,\n                            df.city_id,\n                            df.temp,\n                            df.temp_min,\n                            df.temp_max,\n                            df.pressure,\n                            df.humidity,\n                            df.visibility,\n                            df.wind_speed,\n                            df.wind_deg,\n                            df.wind_gust,\n                            df.clouds_all\n                        )\n    start = datetime.fromtimestamp(df.selectExpr(\"min(dt)\").first()[0])\n    end = datetime.fromtimestamp(df.selectExpr(\"max(dt)\").first()[0])\n    \n    return df_fact, start, end"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ddbd6727-41ad-44a7-b6f4-e80631f808fc","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# df_log = spark.table('weather_log_table')\n# df_log = df_log.where(col(\"load_type\")=='PROCESSED').sort('created_on', ascending=False)\n\n# df = spark.table('processed_weather')\n# a, b = df.withColumn('timeID', hour('created_on')).withColumn('Date', col('created_on').cast('date')).sort('timeID', ascending=False).limit(5).select('timeID', 'Date').first()\n# display(df_log)\n# display(df)\n# # display(df_new)\n# b= str(b).replace('-', '') \n# print(a, b)\n\n\n# # query = f\"select * from (select *, to_date(date) as nd from processed_weather) where nd='{b}'\"\n# # display(spark.sql(query))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"34caa900-eba5-4dd0-a332-9c8b184ece61","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"fact_weather_utils","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":3672398024316820,"dataframes":["_sqldf"]}},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
